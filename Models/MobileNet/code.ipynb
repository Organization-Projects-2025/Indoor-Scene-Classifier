{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae07bb0-ad5f-49a1-9185-d2ccacdc975f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Regenerated CSV with 12335 images\n",
      "Total images: 12335, Classes: label\n",
      "living room    2621\n",
      "dining room    2605\n",
      "bed            2445\n",
      "bath           2430\n",
      "kitchen        2234\n",
      "Name: count, dtype: int64\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_11  (None, 1280)             0         \n",
      " 66 (GlobalAveragePooling2D)                                     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               655872    \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,916,421\n",
      "Trainable params: 1,390,917\n",
      "Non-trainable params: 1,525,504\n",
      "_________________________________________________________________\n",
      "Epoch 1/140\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0969s vs `on_train_batch_end` time: 0.1923s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 05:25:49,475 - WARNING - Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0969s vs `on_train_batch_end` time: 0.1923s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 34s 131ms/step - loss: 0.5803 - accuracy: 0.7937 - val_loss: 12.6877 - val_accuracy: 0.2623 - lr: 0.0010\n",
      "Epoch 2/140\n",
      "124/124 [==============================] - 18s 147ms/step - loss: 0.3727 - accuracy: 0.8695 - val_loss: 14.7284 - val_accuracy: 0.3624 - lr: 0.0010\n",
      "Epoch 3/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.2914 - accuracy: 0.8999 - val_loss: 13.5066 - val_accuracy: 0.3656 - lr: 0.0010\n",
      "Epoch 4/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.2385 - accuracy: 0.9153 - val_loss: 7.4277 - val_accuracy: 0.5116 - lr: 0.0010\n",
      "Epoch 5/140\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.1879 - accuracy: 0.9336 - val_loss: 10.0992 - val_accuracy: 0.4702 - lr: 0.0010\n",
      "Epoch 6/140\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.1692 - accuracy: 0.9408 - val_loss: 9.3952 - val_accuracy: 0.4852 - lr: 0.0010\n",
      "Epoch 7/140\n",
      "124/124 [==============================] - 7s 54ms/step - loss: 0.1124 - accuracy: 0.9617 - val_loss: 11.0545 - val_accuracy: 0.4495 - lr: 0.0010\n",
      "Epoch 8/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0974 - accuracy: 0.9676 - val_loss: 25.2494 - val_accuracy: 0.3352 - lr: 0.0010\n",
      "Epoch 9/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.1010 - accuracy: 0.9617 - val_loss: 16.8432 - val_accuracy: 0.2708 - lr: 0.0010\n",
      "Epoch 10/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0871 - accuracy: 0.9705 - val_loss: 11.7570 - val_accuracy: 0.3916 - lr: 0.0010\n",
      "Epoch 11/140\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.0456 - accuracy: 0.9853 - val_loss: 9.0997 - val_accuracy: 0.4674 - lr: 6.0000e-04\n",
      "Epoch 12/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0221 - accuracy: 0.9930 - val_loss: 9.8915 - val_accuracy: 0.4662 - lr: 6.0000e-04\n",
      "Epoch 13/140\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.0236 - accuracy: 0.9920 - val_loss: 7.5376 - val_accuracy: 0.5176 - lr: 6.0000e-04\n",
      "Epoch 14/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0265 - accuracy: 0.9903 - val_loss: 3.6530 - val_accuracy: 0.6794 - lr: 6.0000e-04\n",
      "Epoch 15/140\n",
      "124/124 [==============================] - 7s 57ms/step - loss: 0.0197 - accuracy: 0.9929 - val_loss: 2.2515 - val_accuracy: 0.7665 - lr: 6.0000e-04\n",
      "Epoch 16/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0186 - accuracy: 0.9944 - val_loss: 2.4422 - val_accuracy: 0.7511 - lr: 6.0000e-04\n",
      "Epoch 17/140\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.0256 - accuracy: 0.9909 - val_loss: 5.9834 - val_accuracy: 0.5683 - lr: 6.0000e-04\n",
      "Epoch 18/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0240 - accuracy: 0.9922 - val_loss: 4.4170 - val_accuracy: 0.6457 - lr: 6.0000e-04\n",
      "Epoch 19/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0284 - accuracy: 0.9909 - val_loss: 1.8626 - val_accuracy: 0.8091 - lr: 6.0000e-04\n",
      "Epoch 20/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0229 - accuracy: 0.9919 - val_loss: 1.5220 - val_accuracy: 0.8350 - lr: 6.0000e-04\n",
      "Epoch 21/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0237 - accuracy: 0.9910 - val_loss: 1.8040 - val_accuracy: 0.8075 - lr: 6.0000e-04\n",
      "Epoch 22/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0304 - accuracy: 0.9899 - val_loss: 1.9584 - val_accuracy: 0.8103 - lr: 6.0000e-04\n",
      "Epoch 23/140\n",
      "124/124 [==============================] - 7s 54ms/step - loss: 0.0326 - accuracy: 0.9868 - val_loss: 1.8566 - val_accuracy: 0.8127 - lr: 6.0000e-04\n",
      "Epoch 24/140\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.0189 - accuracy: 0.9931 - val_loss: 1.3959 - val_accuracy: 0.8265 - lr: 6.0000e-04\n",
      "Epoch 25/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0345 - accuracy: 0.9872 - val_loss: 1.4509 - val_accuracy: 0.8172 - lr: 6.0000e-04\n",
      "Epoch 26/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0298 - accuracy: 0.9903 - val_loss: 1.7158 - val_accuracy: 0.8091 - lr: 6.0000e-04\n",
      "Epoch 27/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0213 - accuracy: 0.9914 - val_loss: 1.2930 - val_accuracy: 0.8269 - lr: 6.0000e-04\n",
      "Epoch 28/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0157 - accuracy: 0.9940 - val_loss: 1.3853 - val_accuracy: 0.8338 - lr: 6.0000e-04\n",
      "Epoch 29/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0241 - accuracy: 0.9912 - val_loss: 1.1173 - val_accuracy: 0.8752 - lr: 6.0000e-04\n",
      "Epoch 30/140\n",
      "124/124 [==============================] - 7s 54ms/step - loss: 0.0170 - accuracy: 0.9937 - val_loss: 1.1594 - val_accuracy: 0.8589 - lr: 6.0000e-04\n",
      "Epoch 31/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0174 - accuracy: 0.9927 - val_loss: 1.4241 - val_accuracy: 0.8435 - lr: 6.0000e-04\n",
      "Epoch 32/140\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.0196 - accuracy: 0.9934 - val_loss: 1.0625 - val_accuracy: 0.8703 - lr: 6.0000e-04\n",
      "Epoch 33/140\n",
      "124/124 [==============================] - 7s 54ms/step - loss: 0.0283 - accuracy: 0.9898 - val_loss: 1.3201 - val_accuracy: 0.8687 - lr: 6.0000e-04\n",
      "Epoch 34/140\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.0258 - accuracy: 0.9911 - val_loss: 1.1324 - val_accuracy: 0.8646 - lr: 6.0000e-04\n",
      "Epoch 35/140\n",
      "124/124 [==============================] - 7s 54ms/step - loss: 0.0132 - accuracy: 0.9945 - val_loss: 1.1474 - val_accuracy: 0.8666 - lr: 6.0000e-04\n",
      "Epoch 36/140\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 1.1989 - val_accuracy: 0.8492 - lr: 6.0000e-04\n",
      "Epoch 37/140\n",
      "124/124 [==============================] - 7s 54ms/step - loss: 0.0189 - accuracy: 0.9929 - val_loss: 1.1799 - val_accuracy: 0.8581 - lr: 6.0000e-04\n",
      "Epoch 38/140\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.0186 - accuracy: 0.9931 - val_loss: 1.1059 - val_accuracy: 0.8593 - lr: 6.0000e-04\n",
      "Epoch 39/140\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.0095 - accuracy: 0.9961 - val_loss: 0.9438 - val_accuracy: 0.8768 - lr: 3.6000e-04\n",
      "Epoch 40/140\n",
      "124/124 [==============================] - 7s 54ms/step - loss: 0.0065 - accuracy: 0.9973 - val_loss: 0.9713 - val_accuracy: 0.8792 - lr: 3.6000e-04\n",
      "Epoch 41/140\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.0050 - accuracy: 0.9974 - val_loss: 0.9364 - val_accuracy: 0.8829 - lr: 3.6000e-04\n",
      "Epoch 42/140\n",
      "124/124 [==============================] - 7s 54ms/step - loss: 0.0051 - accuracy: 0.9979 - val_loss: 0.9276 - val_accuracy: 0.8800 - lr: 3.6000e-04\n",
      "Epoch 43/140\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.0162 - accuracy: 0.9939 - val_loss: 0.9405 - val_accuracy: 0.8764 - lr: 3.6000e-04\n",
      "Epoch 44/140\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.0069 - accuracy: 0.9967 - val_loss: 0.8904 - val_accuracy: 0.8824 - lr: 3.6000e-04\n",
      "Epoch 45/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0053 - accuracy: 0.9972 - val_loss: 0.8263 - val_accuracy: 0.8865 - lr: 3.6000e-04\n",
      "Epoch 46/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0062 - accuracy: 0.9971 - val_loss: 0.8736 - val_accuracy: 0.8906 - lr: 3.6000e-04\n",
      "Epoch 47/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0066 - accuracy: 0.9972 - val_loss: 0.8829 - val_accuracy: 0.8914 - lr: 3.6000e-04\n",
      "Epoch 48/140\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.0063 - accuracy: 0.9966 - val_loss: 1.0167 - val_accuracy: 0.8816 - lr: 3.6000e-04\n",
      "Epoch 49/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 1.1394 - val_accuracy: 0.8820 - lr: 3.6000e-04\n",
      "Epoch 50/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0065 - accuracy: 0.9967 - val_loss: 1.0072 - val_accuracy: 0.8829 - lr: 3.6000e-04\n",
      "Epoch 51/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0075 - accuracy: 0.9966 - val_loss: 1.1117 - val_accuracy: 0.8829 - lr: 3.6000e-04\n",
      "Epoch 52/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0059 - accuracy: 0.9977 - val_loss: 1.0216 - val_accuracy: 0.8853 - lr: 2.1600e-04\n",
      "Epoch 53/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0047 - accuracy: 0.9975 - val_loss: 0.9417 - val_accuracy: 0.8922 - lr: 2.1600e-04\n",
      "Epoch 54/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0034 - accuracy: 0.9983 - val_loss: 0.9195 - val_accuracy: 0.8926 - lr: 2.1600e-04\n",
      "Epoch 55/140\n",
      "124/124 [==============================] - 7s 54ms/step - loss: 0.0039 - accuracy: 0.9975 - val_loss: 0.9291 - val_accuracy: 0.8865 - lr: 2.1600e-04\n",
      "Epoch 56/140\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.0035 - accuracy: 0.9981 - val_loss: 0.9124 - val_accuracy: 0.8893 - lr: 2.1600e-04\n",
      "Epoch 57/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0030 - accuracy: 0.9984 - val_loss: 0.8902 - val_accuracy: 0.8914 - lr: 2.1600e-04\n",
      "Epoch 58/140\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.0031 - accuracy: 0.9984 - val_loss: 0.8836 - val_accuracy: 0.8893 - lr: 1.2960e-04\n",
      "Epoch 59/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0029 - accuracy: 0.9982 - val_loss: 0.8646 - val_accuracy: 0.8910 - lr: 1.2960e-04\n",
      "Epoch 60/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 0.8411 - val_accuracy: 0.8942 - lr: 1.2960e-04\n",
      "Epoch 61/140\n",
      "124/124 [==============================] - 7s 54ms/step - loss: 0.0027 - accuracy: 0.9985 - val_loss: 0.8421 - val_accuracy: 0.8930 - lr: 1.2960e-04\n",
      "Epoch 62/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0028 - accuracy: 0.9985 - val_loss: 0.8401 - val_accuracy: 0.8914 - lr: 1.2960e-04\n",
      "Epoch 63/140\n",
      "124/124 [==============================] - 7s 54ms/step - loss: 0.0032 - accuracy: 0.9982 - val_loss: 0.8456 - val_accuracy: 0.8946 - lr: 1.2960e-04\n",
      "Epoch 64/140\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.0026 - accuracy: 0.9983 - val_loss: 0.8387 - val_accuracy: 0.8950 - lr: 7.7760e-05\n",
      "Epoch 65/140\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.0027 - accuracy: 0.9984 - val_loss: 0.8398 - val_accuracy: 0.8979 - lr: 7.7760e-05\n",
      "Epoch 66/140\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.0024 - accuracy: 0.9985 - val_loss: 0.8384 - val_accuracy: 0.8950 - lr: 7.7760e-05\n",
      "Epoch 67/140\n",
      "124/124 [==============================] - 7s 54ms/step - loss: 0.0026 - accuracy: 0.9981 - val_loss: 0.8400 - val_accuracy: 0.8966 - lr: 7.7760e-05\n",
      "Epoch 68/140\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.0032 - accuracy: 0.9981 - val_loss: 0.8437 - val_accuracy: 0.8942 - lr: 7.7760e-05\n",
      "Epoch 69/140\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 0.8459 - val_accuracy: 0.8946 - lr: 7.7760e-05\n",
      "Epoch 70/140\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.0025 - accuracy: 0.9990 - val_loss: 0.8430 - val_accuracy: 0.8962 - lr: 4.6656e-05\n",
      "Epoch 71/140\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.0025 - accuracy: 0.9981 - val_loss: 0.8452 - val_accuracy: 0.8958 - lr: 4.6656e-05\n",
      "Epoch 72/140\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.0029 - accuracy: 0.9983 - val_loss: 0.8481 - val_accuracy: 0.8958 - lr: 4.6656e-05\n",
      "Epoch 73/140\n",
      "124/124 [==============================] - 7s 60ms/step - loss: 0.0026 - accuracy: 0.9982 - val_loss: 0.8590 - val_accuracy: 0.8954 - lr: 4.6656e-05\n",
      "Epoch 74/140\n",
      "124/124 [==============================] - 7s 60ms/step - loss: 0.0027 - accuracy: 0.9980 - val_loss: 0.8651 - val_accuracy: 0.8958 - lr: 4.6656e-05\n",
      "Epoch 75/140\n",
      "124/124 [==============================] - 7s 57ms/step - loss: 0.0029 - accuracy: 0.9983 - val_loss: 0.8652 - val_accuracy: 0.8962 - lr: 4.6656e-05\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.8263 - accuracy: 0.8865\n",
      "Validation Loss: 0.8263, Accuracy: 0.8865\n",
      "3/3 [==============================] - 5s 353ms/step\n",
      "Sample Predictions:\n",
      "('living room', 'living room')\n",
      "('bath', 'bath')\n",
      "('bath', 'bath')\n",
      "('bath', 'bath')\n",
      "('bed', 'bed')\n",
      "('bath', 'bath')\n",
      "('dining room', 'dining room')\n",
      "('kitchen', 'kitchen')\n",
      "('bed', 'bed')\n",
      "('bed', 'bed')\n",
      "31/31 [==============================] - 5s 53ms/step\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        bath       0.92      0.93      0.93       486\n",
      "         bed       0.89      0.92      0.91       489\n",
      " dining room       0.85      0.90      0.87       521\n",
      "     kitchen       0.93      0.82      0.87       447\n",
      " living room       0.86      0.86      0.86       524\n",
      "\n",
      "    accuracy                           0.89      2467\n",
      "   macro avg       0.89      0.89      0.89      2467\n",
      "weighted avg       0.89      0.89      0.89      2467\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.utils import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Enable mixed precision\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "set_global_policy('mixed_float16')\n",
    "\n",
    "# Enable XLA for GPU optimization\n",
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Paths for dataset\n",
    "CSV_PATH = \"../Dataset/image_labels.csv\"\n",
    "IMG_DIR = \"../Dataset/interior\"\n",
    "IMG_HEIGHT, IMG_WIDTH = 224, 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 140\n",
    "\n",
    "# Generate a CSV file mapping image paths to their labels\n",
    "def regenerate_csv(image_dir, output_file):\n",
    "    classes = ['bath', 'bed', 'dining room', 'kitchen', 'living room']\n",
    "    class_variations = {\n",
    "        'bath': ['bath', 'bathroom'], 'bed': ['bed', 'bedroom'],\n",
    "        'dining room': ['dining', 'dining_room', 'diningroom', 'din'],\n",
    "        'kitchen': ['kitchen'], 'living room': ['living', 'living_room', 'livingroom']\n",
    "    }\n",
    "    data = []\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            matched = False\n",
    "            for cls in classes:\n",
    "                for variation in class_variations[cls]:\n",
    "                    if variation.lower() in filename.lower():\n",
    "                        data.append({'image_path': os.path.join(image_dir, filename), 'label': cls})\n",
    "                        matched = True\n",
    "                        break\n",
    "                if matched:\n",
    "                    break\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Regenerated CSV with {len(df)} images\")\n",
    "    return df\n",
    "\n",
    "# Verify that all image paths in the CSV exist\n",
    "def verify_data(csv_path, img_dir):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"Total images: {len(df)}, Classes: {df['label'].value_counts()}\")\n",
    "    missing = [path for path in df['image_path'] if not os.path.exists(path)]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing files: {missing}\")\n",
    "\n",
    "# Load and preprocess the dataset for training\n",
    "def load_and_preprocess_data(csv_path, img_dir):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['label_encoded'] = label_encoder.fit_transform(df['label'])\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    \n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(df['label_encoded']), y=df['label_encoded'])\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "    def load_image(image_path, label):\n",
    "        img = tf.io.read_file(image_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.cast(img, tf.float32)\n",
    "        img = img / 255.0\n",
    "        return img, label\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (train_df['image_path'], tf.keras.utils.to_categorical(train_df['label_encoded'], num_classes))\n",
    "    ).map(load_image, num_parallel_calls=tf.data.AUTOTUNE).cache().shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (val_df['image_path'], tf.keras.utils.to_categorical(val_df['label_encoded'], num_classes))\n",
    "    ).map(load_image, num_parallel_calls=tf.data.AUTOTUNE).cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    return train_dataset, val_dataset, num_classes, label_encoder, val_df, class_weight_dict\n",
    "\n",
    "# Build the pretrained MobileNetV2 model\n",
    "def build_pretrained_model(num_classes):\n",
    "    base_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:-10]:\n",
    "        layer.trainable = False\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax', dtype='float32')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Plot the training history\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for metric in ['accuracy', 'loss']:\n",
    "        plt.subplot(1, 2, 1 if metric == 'accuracy' else 2)\n",
    "        plt.plot(history.history[metric], label=f'Training {metric.capitalize()}')\n",
    "        plt.plot(history.history[f'val_{metric}'], label=f'Validation {metric.capitalize()}')\n",
    "        plt.title(f'Training and Validation {metric.capitalize()}')\n",
    "        plt.legend()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.close()\n",
    "\n",
    "# Plot the confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, classes):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "# Main function to execute the pipeline\n",
    "def main():\n",
    "    df = regenerate_csv(IMG_DIR, CSV_PATH)\n",
    "    if df is None:\n",
    "        return\n",
    "    \n",
    "    verify_data(CSV_PATH, IMG_DIR)\n",
    "    \n",
    "    train_dataset, val_dataset, num_classes, label_encoder, val_df, class_weight_dict = load_and_preprocess_data(CSV_PATH, IMG_DIR)\n",
    "    \n",
    "    model = build_pretrained_model(num_classes)\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.build((None, IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    model.summary()\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.6, patience=6, min_lr=1e-6),\n",
    "        CSVLogger('training_log.csv', append=True)\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_dataset, epochs=EPOCHS, validation_data=val_dataset,\n",
    "        callbacks=callbacks, class_weight=class_weight_dict, verbose=1\n",
    "    )\n",
    "    \n",
    "    val_loss, val_accuracy = model.evaluate(val_dataset)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "    model.save('model.keras')\n",
    "    np.save('label_encoder_classes.npy', label_encoder.classes_)\n",
    "    \n",
    "    plot_training_history(history)\n",
    "    \n",
    "    val_images, val_labels = next(iter(val_dataset))\n",
    "    predictions = model.predict(val_images)\n",
    "    predicted_labels = label_encoder.inverse_transform(np.argmax(predictions, axis=1))\n",
    "    true_labels = label_encoder.inverse_transform(np.argmax(val_labels, axis=1))\n",
    "    print(\"Sample Predictions:\", *[(t, p) for t, p in zip(true_labels[:10], predicted_labels[:10])], sep='\\n')\n",
    "    \n",
    "    val_predictions = model.predict(val_dataset)\n",
    "    val_pred_labels = np.argmax(val_predictions, axis=1)\n",
    "    val_true_labels = np.argmax(np.concatenate([y for _, y in val_dataset]), axis=1)\n",
    "    report = classification_report(val_true_labels, val_pred_labels, target_names=label_encoder.classes_)\n",
    "    print(\"\\nClassification Report:\\n\", report)\n",
    "    \n",
    "    with open('classification_report.txt', 'w') as f:\n",
    "        f.write(report)\n",
    "    \n",
    "    plot_confusion_matrix(val_true_labels, val_pred_labels, label_encoder.classes_)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
