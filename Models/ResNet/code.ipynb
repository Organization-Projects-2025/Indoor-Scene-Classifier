{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f2c9b7-ad49-4ae2-9542-a3cf6ee03956",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3060 Laptop GPU, compute capability 8.6\n",
      "Num GPUs Available:  1\n",
      "Regenerated CSV with 12335 images\n",
      "Total images: 12335, Classes: label\n",
      "living room    2621\n",
      "dining room    2605\n",
      "bed            2445\n",
      "bath           2430\n",
      "kitchen        2234\n",
      "Name: count, dtype: int64\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " random_flip (RandomFlip)    (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " random_rotation (RandomRota  (None, 224, 224, 3)      0         \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " random_zoom (RandomZoom)    (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 5125      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,691,013\n",
      "Trainable params: 11,034,629\n",
      "Non-trainable params: 14,656,384\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "124/124 [==============================] - 289s 2s/step - loss: 9.7554 - accuracy: 0.7591 - val_loss: 5.7511 - val_accuracy: 0.8269 - lr: 3.0000e-04\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 187s 1s/step - loss: 3.7283 - accuracy: 0.8686 - val_loss: 2.4035 - val_accuracy: 0.8711 - lr: 3.0000e-04\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 166s 1s/step - loss: 1.6111 - accuracy: 0.9041 - val_loss: 1.3906 - val_accuracy: 0.8306 - lr: 3.0000e-04\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 169s 1s/step - loss: 0.8322 - accuracy: 0.9177 - val_loss: 0.8106 - val_accuracy: 0.8824 - lr: 3.0000e-04\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 165s 1s/step - loss: 0.4850 - accuracy: 0.9347 - val_loss: 0.7400 - val_accuracy: 0.8764 - lr: 3.0000e-04\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 157s 1s/step - loss: 0.3455 - accuracy: 0.9406 - val_loss: 0.5979 - val_accuracy: 0.8634 - lr: 3.0000e-04\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 156s 1s/step - loss: 0.2572 - accuracy: 0.9490 - val_loss: 0.5074 - val_accuracy: 0.8926 - lr: 3.0000e-04\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 155s 1s/step - loss: 0.2071 - accuracy: 0.9578 - val_loss: 0.5539 - val_accuracy: 0.8792 - lr: 3.0000e-04\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 154s 1s/step - loss: 0.1655 - accuracy: 0.9636 - val_loss: 0.4813 - val_accuracy: 0.9019 - lr: 3.0000e-04\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 153s 1s/step - loss: 0.1492 - accuracy: 0.9677 - val_loss: 0.6253 - val_accuracy: 0.8804 - lr: 3.0000e-04\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 154s 1s/step - loss: 0.1373 - accuracy: 0.9685 - val_loss: 0.4312 - val_accuracy: 0.9068 - lr: 3.0000e-04\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 157s 1s/step - loss: 0.1150 - accuracy: 0.9756 - val_loss: 0.4479 - val_accuracy: 0.9072 - lr: 3.0000e-04\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 156s 1s/step - loss: 0.1190 - accuracy: 0.9745 - val_loss: 0.5441 - val_accuracy: 0.8914 - lr: 3.0000e-04\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 157s 1s/step - loss: 0.1039 - accuracy: 0.9788 - val_loss: 0.4719 - val_accuracy: 0.8983 - lr: 3.0000e-04\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 156s 1s/step - loss: 0.1112 - accuracy: 0.9746 - val_loss: 0.4604 - val_accuracy: 0.9031 - lr: 3.0000e-04\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 158s 1s/step - loss: 0.0858 - accuracy: 0.9830 - val_loss: 0.4839 - val_accuracy: 0.8970 - lr: 3.0000e-04\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 160s 1s/step - loss: 0.0783 - accuracy: 0.9848 - val_loss: 0.5259 - val_accuracy: 0.8970 - lr: 3.0000e-04\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 158s 1s/step - loss: 0.0657 - accuracy: 0.9880 - val_loss: 0.4134 - val_accuracy: 0.9060 - lr: 1.5000e-04\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 158s 1s/step - loss: 0.0474 - accuracy: 0.9915 - val_loss: 0.3828 - val_accuracy: 0.9076 - lr: 1.5000e-04\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 190s 2s/step - loss: 0.0419 - accuracy: 0.9928 - val_loss: 0.4050 - val_accuracy: 0.9108 - lr: 1.5000e-04\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 197s 2s/step - loss: 0.0360 - accuracy: 0.9940 - val_loss: 0.3841 - val_accuracy: 0.9084 - lr: 1.5000e-04\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 206s 2s/step - loss: 0.0308 - accuracy: 0.9956 - val_loss: 0.3664 - val_accuracy: 0.9197 - lr: 1.5000e-04\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 208s 2s/step - loss: 0.0329 - accuracy: 0.9945 - val_loss: 0.4145 - val_accuracy: 0.9100 - lr: 1.5000e-04\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 206s 2s/step - loss: 0.0364 - accuracy: 0.9938 - val_loss: 0.4133 - val_accuracy: 0.9015 - lr: 1.5000e-04\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 199s 2s/step - loss: 0.0320 - accuracy: 0.9947 - val_loss: 0.4145 - val_accuracy: 0.9141 - lr: 1.5000e-04\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 157s 1s/step - loss: 0.0296 - accuracy: 0.9953 - val_loss: 0.4065 - val_accuracy: 0.9137 - lr: 1.5000e-04\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 161s 1s/step - loss: 0.0303 - accuracy: 0.9947 - val_loss: 0.4125 - val_accuracy: 0.9124 - lr: 1.5000e-04\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 160s 1s/step - loss: 0.0241 - accuracy: 0.9965 - val_loss: 0.3559 - val_accuracy: 0.9222 - lr: 7.5000e-05\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 154s 1s/step - loss: 0.0227 - accuracy: 0.9968 - val_loss: 0.3477 - val_accuracy: 0.9189 - lr: 7.5000e-05\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 159s 1s/step - loss: 0.0243 - accuracy: 0.9958 - val_loss: 0.3549 - val_accuracy: 0.9254 - lr: 7.5000e-05\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 157s 1s/step - loss: 0.0202 - accuracy: 0.9970 - val_loss: 0.3383 - val_accuracy: 0.9226 - lr: 7.5000e-05\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 158s 1s/step - loss: 0.0200 - accuracy: 0.9967 - val_loss: 0.3725 - val_accuracy: 0.9165 - lr: 7.5000e-05\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 157s 1s/step - loss: 0.0177 - accuracy: 0.9981 - val_loss: 0.3666 - val_accuracy: 0.9214 - lr: 7.5000e-05\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 153s 1s/step - loss: 0.0202 - accuracy: 0.9971 - val_loss: 0.3674 - val_accuracy: 0.9185 - lr: 7.5000e-05\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 155s 1s/step - loss: 0.0195 - accuracy: 0.9971 - val_loss: 0.3679 - val_accuracy: 0.9201 - lr: 7.5000e-05\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 154s 1s/step - loss: 0.0185 - accuracy: 0.9970 - val_loss: 0.3508 - val_accuracy: 0.9230 - lr: 3.7500e-05\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 156s 1s/step - loss: 0.0165 - accuracy: 0.9972 - val_loss: 0.3495 - val_accuracy: 0.9210 - lr: 3.7500e-05\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 150s 1s/step - loss: 0.0161 - accuracy: 0.9974 - val_loss: 0.3455 - val_accuracy: 0.9218 - lr: 3.7500e-05\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 158s 1s/step - loss: 0.0159 - accuracy: 0.9974 - val_loss: 0.3378 - val_accuracy: 0.9246 - lr: 3.7500e-05\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 157s 1s/step - loss: 0.0155 - accuracy: 0.9977 - val_loss: 0.3268 - val_accuracy: 0.9250 - lr: 3.7500e-05\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 152s 1s/step - loss: 0.0148 - accuracy: 0.9980 - val_loss: 0.3328 - val_accuracy: 0.9258 - lr: 1.8750e-05\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 154s 1s/step - loss: 0.0125 - accuracy: 0.9989 - val_loss: 0.3290 - val_accuracy: 0.9242 - lr: 1.8750e-05\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 152s 1s/step - loss: 0.0126 - accuracy: 0.9983 - val_loss: 0.3369 - val_accuracy: 0.9210 - lr: 1.8750e-05\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 152s 1s/step - loss: 0.0131 - accuracy: 0.9980 - val_loss: 0.3388 - val_accuracy: 0.9234 - lr: 1.8750e-05\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 151s 1s/step - loss: 0.0135 - accuracy: 0.9974 - val_loss: 0.3457 - val_accuracy: 0.9230 - lr: 1.8750e-05\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 148s 1s/step - loss: 0.0136 - accuracy: 0.9975 - val_loss: 0.3344 - val_accuracy: 0.9250 - lr: 1.8750e-05\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 148s 1s/step - loss: 0.0132 - accuracy: 0.9978 - val_loss: 0.3300 - val_accuracy: 0.9262 - lr: 9.3750e-06\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 148s 1s/step - loss: 0.0125 - accuracy: 0.9982 - val_loss: 0.3288 - val_accuracy: 0.9270 - lr: 9.3750e-06\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 148s 1s/step - loss: 0.0119 - accuracy: 0.9982 - val_loss: 0.3298 - val_accuracy: 0.9266 - lr: 9.3750e-06\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 150s 1s/step - loss: 0.0110 - accuracy: 0.9988 - val_loss: 0.3317 - val_accuracy: 0.9266 - lr: 9.3750e-06\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 0.3317 - accuracy: 0.9266\n",
      "Validation Loss: 0.3317, Accuracy: 0.9266\n",
      "3/3 [==============================] - 8s 376ms/step\n",
      "Sample Predictions:\n",
      "('living room', 'living room')\n",
      "('bath', 'bath')\n",
      "('bath', 'bath')\n",
      "('bath', 'bath')\n",
      "('bed', 'bed')\n",
      "('bath', 'bath')\n",
      "('dining room', 'dining room')\n",
      "('kitchen', 'kitchen')\n",
      "('bed', 'bed')\n",
      "('bed', 'bed')\n",
      "31/31 [==============================] - 7s 87ms/step\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        bath       0.95      0.98      0.96       486\n",
      "         bed       0.95      0.94      0.94       489\n",
      " dining room       0.92      0.90      0.91       521\n",
      "     kitchen       0.95      0.91      0.93       447\n",
      " living room       0.88      0.91      0.89       524\n",
      "\n",
      "    accuracy                           0.93      2467\n",
      "   macro avg       0.93      0.93      0.93      2467\n",
      "weighted avg       0.93      0.93      0.93      2467\n",
      "\n",
      "Misclassified examples: 181\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, RandomFlip, RandomRotation, RandomZoom\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet50_preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.utils import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Enable mixed precision to reduce memory usage and speed up training\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "set_global_policy('mixed_float16')\n",
    "\n",
    "# Enable XLA for GPU optimization to improve performance\n",
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "# Set seeds for reproducibility to ensure consistent results across runs\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define paths and hyperparameters\n",
    "CSV_PATH = \"../Dataset/image_labels.csv\"  # Path to the CSV file containing image paths and labels\n",
    "IMG_DIR = \"../Dataset/interior\"           # Directory containing the images\n",
    "IMG_HEIGHT, IMG_WIDTH = 224, 224          # Image dimensions for resizing (ResNet50 expects 224x224)\n",
    "BATCH_SIZE = 32                           # Batch size for training (reduced to manage memory)\n",
    "EPOCHS = 50                               # Maximum number of epochs for training\n",
    "MODEL_NAME = 'resnet50'                   # Model identifier for file naming\n",
    "\n",
    "# Generate a CSV file mapping image paths to their labels\n",
    "def regenerate_csv(image_dir, output_file):\n",
    "    \"\"\"\n",
    "    Scans the image directory, matches filenames to class labels based on predefined variations,\n",
    "    and saves the mapping to a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        image_dir (str): Directory containing the images.\n",
    "        output_file (str): Path to save the generated CSV file.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing image paths and labels.\n",
    "    \"\"\"\n",
    "    classes = ['bath', 'bed', 'dining room', 'kitchen', 'living room']\n",
    "    class_variations = {\n",
    "        'bath': ['bath', 'bathroom'], 'bed': ['bed', 'bedroom'],\n",
    "        'dining room': ['dining', 'dining_room', 'diningroom', 'din'],\n",
    "        'kitchen': ['kitchen'], 'living room': ['living', 'living_room', 'livingroom']\n",
    "    }\n",
    "    data = []\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            matched = False\n",
    "            for cls in classes:\n",
    "                for variation in class_variations[cls]:\n",
    "                    if variation.lower() in filename.lower():\n",
    "                        data.append({'image_path': os.path.join(image_dir, filename), 'label': cls})\n",
    "                        matched = True\n",
    "                        break\n",
    "                if matched:\n",
    "                    break\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Regenerated CSV with {len(df)} images\")\n",
    "    return df\n",
    "\n",
    "# Verify that all image paths in the CSV exist\n",
    "def verify_data(csv_path, img_dir):\n",
    "    \"\"\"\n",
    "    Verifies that all image paths listed in the CSV file exist in the image directory.\n",
    "    \n",
    "    Args:\n",
    "        csv_path (str): Path to the CSV file.\n",
    "        img_dir (str): Directory containing the images.\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If any image file is missing.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"Total images: {len(df)}, Classes: {df['label'].value_counts()}\")\n",
    "    missing = [path for path in df['image_path'] if not os.path.exists(path)]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing files: {missing}\")\n",
    "\n",
    "# Load and preprocess the dataset for training with ResNet50-specific preprocessing\n",
    "def load_and_preprocess_data(csv_path, img_dir):\n",
    "    \"\"\"\n",
    "    Loads the dataset from a CSV file, encodes labels, splits into training and validation sets,\n",
    "    and creates TensorFlow datasets with ResNet50-specific preprocessing.\n",
    "    \n",
    "    Args:\n",
    "        csv_path (str): Path to the CSV file.\n",
    "        img_dir (str): Directory containing the images.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (train_dataset, val_dataset, num_classes, label_encoder, val_df, class_weight_dict)\n",
    "    \"\"\"\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Encode the string labels (e.g., 'bath') into integers (e.g., 0, 1, ...)\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['label_encoded'] = label_encoder.fit_transform(df['label'])\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    \n",
    "    # Split the data into training (80%) and validation (20%) sets with stratification\n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
    "    \n",
    "    # Compute class weights to handle slight imbalances in the dataset\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(df['label_encoded']), y=df['label_encoded'])\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "    \n",
    "    # Define a helper function to load and preprocess an image\n",
    "    def load_image(image_path, label):\n",
    "        img = tf.io.read_file(image_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.cast(img, tf.float32)\n",
    "        # Apply ResNet50-specific preprocessing (normalizes to [-1, 1])\n",
    "        img = resnet50_preprocess(img)\n",
    "        return img, label\n",
    "    \n",
    "    # Create TensorFlow datasets for training and validation with caching, shuffling, batching, and prefetching\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (train_df['image_path'], tf.keras.utils.to_categorical(train_df['label_encoded'], num_classes))\n",
    "    ).map(load_image, num_parallel_calls=tf.data.AUTOTUNE).cache().shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (val_df['image_path'], tf.keras.utils.to_categorical(val_df['label_encoded'], num_classes))\n",
    "    ).map(load_image, num_parallel_calls=tf.data.AUTOTUNE).cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return train_dataset, val_dataset, num_classes, label_encoder, val_df, class_weight_dict\n",
    "\n",
    "# Build the pretrained ResNet50 model\n",
    "def build_pretrained_model(num_classes):\n",
    "    \"\"\"\n",
    "    Builds a ResNet50-based model with data augmentation, a frozen base, and a custom head.\n",
    "    \n",
    "    Args:\n",
    "        num_classes (int): Number of output classes (5 in this case).\n",
    "    \n",
    "    Returns:\n",
    "        tf.keras.Model: Compiled ResNet50 model.\n",
    "    \"\"\"\n",
    "    # Load ResNet50 with ImageNet weights, excluding the top layers\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    \n",
    "    # Freeze most layers to prevent overfitting, unfreeze the last 20 layers for fine-tuning\n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:-20]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Build the model with augmentation layers and a custom head\n",
    "    model = Sequential([\n",
    "        # Data augmentation to improve generalization\n",
    "        RandomFlip(\"horizontal\", seed=42),\n",
    "        RandomRotation(0.1, seed=42),\n",
    "        RandomZoom(0.1, seed=42),\n",
    "        # Base ResNet50 model\n",
    "        base_model,\n",
    "        # Pooling to reduce spatial dimensions\n",
    "        GlobalAveragePooling2D(),\n",
    "        # Dense layer with increased capacity and regularization\n",
    "        Dense(1024, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.5),\n",
    "        # Output layer with softmax for classification\n",
    "        Dense(num_classes, activation='softmax', dtype='float32')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Plot the training history\n",
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plots training and validation accuracy/loss and saves the plot.\n",
    "    \n",
    "    Args:\n",
    "        history: Training history object from model.fit().\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for metric in ['accuracy', 'loss']:\n",
    "        plt.subplot(1, 2, 1 if metric == 'accuracy' else 2)\n",
    "        plt.plot(history.history[metric], label=f'Training {metric.capitalize()}')\n",
    "        plt.plot(history.history[f'val_{metric}'], label=f'Validation {metric.capitalize()}')\n",
    "        plt.title(f'Training and Validation {metric.capitalize()}')\n",
    "        plt.legend()\n",
    "    plt.savefig(f'training_history_{MODEL_NAME}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Plot the confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, classes):\n",
    "    \"\"\"\n",
    "    Generates and saves a confusion matrix heatmap.\n",
    "    \n",
    "    Args:\n",
    "        y_true: True labels.\n",
    "        y_pred: Predicted labels.\n",
    "        classes: List of class names.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig(f'confusion_matrix_{MODEL_NAME}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Main function to execute the pipeline\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Executes the full pipeline: data preparation, model training, evaluation, and visualization.\n",
    "    \"\"\"\n",
    "    # Generate the CSV file with image paths and labels\n",
    "    df = regenerate_csv(IMG_DIR, CSV_PATH)\n",
    "    if df is None:\n",
    "        return\n",
    "    \n",
    "    # Verify that all image paths exist\n",
    "    verify_data(CSV_PATH, IMG_DIR)\n",
    "    \n",
    "    # Load and preprocess the dataset\n",
    "    train_dataset, val_dataset, num_classes, label_encoder, val_df, class_weight_dict = load_and_preprocess_data(CSV_PATH, IMG_DIR)\n",
    "    \n",
    "    # Build the ResNet50 model\n",
    "    model = build_pretrained_model(num_classes)\n",
    "    \n",
    "    # Compile the model with a lower learning rate for fine-tuning\n",
    "    model.compile(optimizer=Adam(learning_rate=3e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.build((None, IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    model.summary()\n",
    "    \n",
    "    # Define callbacks for training\n",
    "    callbacks = [\n",
    "        # Stop training if validation accuracy doesn't improve for 15 epochs\n",
    "        EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True),\n",
    "        # Reduce learning rate if validation accuracy plateaus for 5 epochs\n",
    "        ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, min_lr=1e-6),\n",
    "        # Log training metrics to a CSV file\n",
    "        CSVLogger(f'training_log_{MODEL_NAME}.csv', append=True)\n",
    "    ]\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_dataset, epochs=EPOCHS, validation_data=val_dataset,\n",
    "        callbacks=callbacks, class_weight=class_weight_dict, verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    val_loss, val_accuracy = model.evaluate(val_dataset)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "    # Save the trained model and label encoder\n",
    "    model.save(f'model_{MODEL_NAME}.keras')\n",
    "    np.save('label_encoder_classes.npy', label_encoder.classes_)\n",
    "    \n",
    "    # Plot training and validation accuracy/loss\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    # Get sample predictions to inspect model performance\n",
    "    val_images, val_labels = next(iter(val_dataset))\n",
    "    predictions = model.predict(val_images)\n",
    "    predicted_labels = label_encoder.inverse_transform(np.argmax(predictions, axis=1))\n",
    "    true_labels = label_encoder.inverse_transform(np.argmax(val_labels, axis=1))\n",
    "    print(\"Sample Predictions:\", *[(t, p) for t, p in zip(true_labels[:10], predicted_labels[:10])], sep='\\n')\n",
    "    \n",
    "    # Generate a classification report and confusion matrix\n",
    "    val_predictions = model.predict(val_dataset)\n",
    "    val_pred_labels = np.argmax(val_predictions, axis=1)\n",
    "    val_true_labels = np.argmax(np.concatenate([y for _, y in val_dataset]), axis=1)\n",
    "    report = classification_report(val_true_labels, val_pred_labels, target_names=label_encoder.classes_)\n",
    "    print(\"\\nClassification Report:\\n\", report)\n",
    "    \n",
    "    # Save the classification report\n",
    "    with open(f'classification_report_{MODEL_NAME}.txt', 'w') as f:\n",
    "        f.write(report)\n",
    "    \n",
    "    # Plot and save the confusion matrix\n",
    "    plot_confusion_matrix(val_true_labels, val_pred_labels, label_encoder.classes_)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
